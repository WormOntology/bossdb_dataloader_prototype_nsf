{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results in: /Users/jnaiman/Downloads/tmp/wormfindr/wormOntologyNSF/multiClassWorm256/eval_images/\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "verbose=True\n",
    "\n",
    "EVAL = False \n",
    "PLOT_LOSS = False\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "import config\n",
    "print('results in:', config.EVAL_IMG_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/WormOntology/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape= (303, 8346, 12830)\n",
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import UNET\n",
    "#from utils import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "#from cityscapesscripts.helpers.labels import trainId2label as t2l\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from dataset import BossDBSliceDataset\n",
    "# for bossdb\n",
    "from intern import array\n",
    "\n",
    "# for updates\n",
    "from importlib import reload\n",
    "import config\n",
    "reload(config)\n",
    "from numpy import random, column_stack\n",
    "\n",
    "# get dataset URI\n",
    "boss_uri_images = config.IMAGE_DATASET_URI\n",
    "boss_uri_masks = config.SEGMASK_DATASET_URI\n",
    "# JPN -- have to get dataset size and centroids\n",
    "channel = array(boss_uri_images)\n",
    "# get shape\n",
    "shape = channel.shape\n",
    "print('dataset shape=', shape)\n",
    "\n",
    "# select a set of centroids randomly\n",
    "ncentroid_train = config.NCENTROID_TRAIN\n",
    "ncentroid_test = config.NCENTROID_TEST\n",
    "zshift = config.ZSHIFT\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_images(tensor_pred, folder, image_name, multiclass=True):\n",
    "    if y.shape[0] == 1: # only one layer\n",
    "        tensor_pred = transforms.ToPILImage()(tensor_pred.byte())\n",
    "        filename = f\"{folder}\\{image_name}.png\"\n",
    "        tensor_pred.save(filename)\n",
    "    else:\n",
    "        for i in range(tensor_pred.shape[0]): # for each one\n",
    "            tensor_pred_out = transforms.ToPILImage()(tensor_pred[i,:,:].byte())\n",
    "            image_name_out = image_name + '_batch' + str(i)\n",
    "            filename = f\"{folder}\\{image_name_out}.png\"\n",
    "            filename = filename.replace(r'//',r'/')\n",
    "            filename = filename.replace('\\\\','')\n",
    "            tensor_pred_out.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(data, model, location):    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(tqdm(data)):\n",
    "\n",
    "            #X, y, s = batch # here 's' is the name of the file stored in the root directory\n",
    "            X, y = batch # JPN\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # save images\n",
    "            save_as_images(X, location, 'image_' + str(idx), multiclass=True)   \n",
    "            # save gt             \n",
    "            save_as_images(y, location, 'gtmask_' + str(idx), multiclass=True)   \n",
    "\n",
    "            predictions = model(X) \n",
    "            \n",
    "            predictions = torch.nn.functional.softmax(predictions, dim=1)\n",
    "            pred_labels = torch.argmax(predictions, dim=1) \n",
    "            pred_labels = pred_labels.float()\n",
    "\n",
    "            # Remapping the labels\n",
    "            pred_labels = pred_labels.to('cpu')\n",
    "            ##pred_labels.apply_(lambda x: t2l[x].id)\n",
    "            pred_labels = pred_labels.to(device)   \n",
    "\n",
    "            # Resizing predicted images too original size\n",
    "            #pred_labels = transforms.Resize((1024, 2048))(pred_labels)             \n",
    "\n",
    "            # Configure filename & location to save predictions as images\n",
    "            save_as_images(pred_labels, location, 'predMask_' + str(idx), multiclass=True)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving test centroids to /Users/jnaiman/Downloads/tmp/wormfindr/wormOntologyNSF/multiClassWorm256/test_paths.txt ...\n",
      "image,mask uri= bossdb://white1986/n2u/em bossdb://white1986/n2u/seg\n"
     ]
    }
   ],
   "source": [
    "# get test paths\n",
    "z = random.randint(config.ZMIN,config.ZMAX-1,size=ncentroid_test)\n",
    "y = random.randint(config.YMIN+config.INPUT_IMAGE_WIDTH//2,config.YMAX-config.INPUT_IMAGE_WIDTH//2,size=ncentroid_test)\n",
    "x = random.randint(config.XMIN+config.INPUT_IMAGE_WIDTH//2,config.XMAX-config.INPUT_IMAGE_WIDTH//2,size=ncentroid_test)\n",
    "centroids_test = column_stack([z,y,x])\n",
    "\n",
    "# save test centroids\n",
    "path_save = config.EVAL_IMG_PATHS\n",
    "print(\"[INFO] saving test centroids to \"+path_save+\" ...\")\n",
    "f = open(path_save, \"w\")\n",
    "#print(centroids_test.astype('str').tolist())\n",
    "for t in centroids_test:\n",
    "    f.write(str(t)+'\\n')\n",
    "#f.write(\"\\n\".join(centroids_test.astype('str').tolist()))\n",
    "f.close()\n",
    "\n",
    "# create the train and test datasets\n",
    "testDS = BossDBSliceDataset(image_boss_uri=boss_uri_images, mask_boss_uri=boss_uri_masks, \n",
    "                                centroid_list_zyx = centroids_test, \n",
    "                                boss_config = None, # None for public dataset\n",
    "                                px_radius_yx = [config.INPUT_IMAGE_WIDTH//2,config.INPUT_IMAGE_WIDTH//2],\n",
    "                                zshift=zshift, verbose=verbose)\n",
    "val_set = DataLoader(testDS, shuffle=False,\n",
    "    batch_size=config.BATCH_SIZE, pin_memory=config.PIN_MEMORY,\n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/bwcvd_4177q4872gxghn7p9r0000gq/T/ipykernel_30146/1356453059.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(config.MODEL_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jnaiman/Downloads/tmp/wormfindr/wormOntologyNSF/multiClassWorm256/unet_model.pth has been loaded and initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [04:37<04:37, 277.79s/it]"
     ]
    }
   ],
   "source": [
    "print('Data has been loaded!')\n",
    "\n",
    "net = UNET(in_channels=3, classes=config.NUM_CLASSES).to(device)\n",
    "checkpoint = torch.load(config.MODEL_PATH)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net.eval()\n",
    "print(f'{config.MODEL_PATH} has been loaded and initialized')\n",
    "save_predictions(val_set, net, config.EVAL_IMG_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, batch in enumerate(tqdm(val_set)):\n",
    "#     import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WormOntology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
